#!/usr/bin/env python3
"""
SOP Analyzer - –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ .sop —Ñ–∞–π–ª–æ–≤
"""

import json
import zipfile
import zlib
import argparse
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import datetime

@dataclass
class RecordStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–ø–∏—Å—è–º"""
    total: int = 0
    deletes: int = 0
    strong_overwrites: int = 0

@dataclass
class TableInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∞–±–ª–∏—Ü–µ"""
    name: str
    record_count: int
    actions: Dict[str, int]

class SOPAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä SOP —Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self, sop_file_path: str):
        self.sop_file_path = Path(sop_file_path)
        self._data = None
    
    def load_data(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ SOP —Ñ–∞–π–ª–∞"""
        if self._data is not None:
            return self._data
            
        if not self.sop_file_path.exists():
            raise FileNotFoundError(f"SOP —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.sop_file_path}")
        
        try:
            with zipfile.ZipFile(self.sop_file_path, 'r') as sop_zip:
                # –ò—â–µ–º —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏
                data_files = [f for f in sop_zip.namelist() if f.endswith('.data')]
                if not data_files:
                    raise ValueError("–í –∞—Ä—Ö–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ (.data)")
                
                # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ .data —Ñ–∞–π–ª–∞
                with sop_zip.open(data_files[0]) as data_file:
                    compressed_data = data_file.read()
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–∏
                decompressed_data = self._decompress_data(compressed_data)
                self._data = json.loads(decompressed_data.decode('utf-8'))
                
                return self._data
                
        except zipfile.BadZipFile:
            raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ZIP –∞—Ä—Ö–∏–≤")
        except json.JSONDecodeError as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
    
    def _decompress_data(self, compressed_data: bytes) -> bytes:
        """–î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤"""
        methods = [
            self._try_raw_deflate,
            self._try_zlib_deflate,
            self._try_gzip_format,
            self._try_with_headers
        ]
        
        for method in methods:
            try:
                result = method(compressed_data)
                print(f"‚úì –£—Å–ø–µ—à–Ω–∞—è –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—è –º–µ—Ç–æ–¥–æ–º: {method.__name__}")
                return result
            except Exception as e:
                print(f"‚úó –ú–µ—Ç–æ–¥ {method.__name__} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                continue
        
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ –æ–¥–Ω–∏–º –∏–∑ –º–µ—Ç–æ–¥–æ–≤")
    
    def _try_raw_deflate(self, data: bytes) -> bytes:
        """–ü–æ–ø—ã—Ç–∫–∞ RAW Deflate –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–∏"""
        return zlib.decompress(data, -15)
    
    def _try_zlib_deflate(self, data: bytes) -> bytes:
        """–ü–æ–ø—ã—Ç–∫–∞ Zlib –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–∏"""
        return zlib.decompress(data)
    
    def _try_gzip_format(self, data: bytes) -> bytes:
        """–ü–æ–ø—ã—Ç–∫–∞ –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –∫–∞–∫ GZIP —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º"""
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ–π gzip –∑–∞–≥–æ–ª–æ–≤–æ–∫
        gzip_header = b'\x1f\x8b\x08\x00\x00\x00\x00\x00\x02\xff'
        gzip_data = gzip_header + data + b'\x00\x00\x00\x00\x00\x00\x00\x00'
        return zlib.decompress(gzip_data, 15 + 32)
    
    def _try_with_headers(self, data: bytes) -> bytes:
        """–ü–æ–ø—ã—Ç–∫–∞ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏"""
        headers_to_try = [
            b'',  # –ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            b'\x78\x9c',  # Zlib –∑–∞–≥–æ–ª–æ–≤–æ–∫
            b'\x78\x01',  # Zlib –∑–∞–≥–æ–ª–æ–≤–æ–∫
            b'\x78\xda',  # Zlib –∑–∞–≥–æ–ª–æ–≤–æ–∫
        ]
        
        for header in headers_to_try:
            try:
                return zlib.decompress(header + data)
            except:
                continue
        
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —É–±—Ä–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–µ –ª–∏—à–Ω–∏–µ –±–∞–π—Ç—ã
        for i in range(min(10, len(data))):
            try:
                return zlib.decompress(data[i:], -15)
            except:
                continue
        
        raise ValueError("–í—Å–µ –º–µ—Ç–æ–¥—ã —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏")
    
    def get_metadata(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç–∞"""
        data = self.load_data()
        return {
            'name': data.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
            'pack_application_id': data.get('pack_application_id', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
            'timestamp': data.get('timestamp'),
            'version': data.get('version', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        }
    
    def analyze_records(self) -> RecordStats:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–ø–∏—Å–µ–π"""
        data = self.load_data()
        records = data.get('records', [])
        
        stats = RecordStats(total=len(records))
        
        for record in records:
            if record.get('action') == 'delete':
                stats.deletes += 1
            if record.get('is_strong_overwrite') is True:
                stats.strong_overwrites += 1
        
        return stats
    
    def analyze_tables(self) -> List[TableInfo]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü –∏ –∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        data = self.load_data()
        records = data.get('records', [])
        
        tables = {}
        
        for record in records:
            table_name = record.get('table_name', 'unknown')
            action = record.get('action', 'unknown')
            
            if table_name not in tables:
                tables[table_name] = {'count': 0, 'actions': {}}
            
            tables[table_name]['count'] += 1
            tables[table_name]['actions'][action] = tables[table_name]['actions'].get(action, 0) + 1
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–∞–ø–∏—Å–µ–π
        sorted_tables = sorted(tables.items(), key=lambda x: x[1]['count'], reverse=True)
        
        return [
            TableInfo(
                name=table_name,
                record_count=table_data['count'],
                actions=table_data['actions']
            )
            for table_name, table_data in sorted_tables
        ]
    
    def get_actions_summary(self) -> Dict[str, int]:
        """–°–≤–æ–¥–∫–∞ –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º"""
        data = self.load_data()
        records = data.get('records', [])
        
        actions = {}
        for record in records:
            action = record.get('action', 'unknown')
            actions[action] = actions.get(action, 0) + 1
        
        return actions
    
    def get_raw_data_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)"""
        try:
            with zipfile.ZipFile(self.sop_file_path, 'r') as sop_zip:
                data_files = [f for f in sop_zip.namelist() if f.endswith('.data')]
                if not data_files:
                    return {'error': 'No .data file found'}
                
                with sop_zip.open(data_files[0]) as data_file:
                    raw_data = data_file.read()
                
                return {
                    'data_file_size': len(raw_data),
                    'first_10_bytes': raw_data[:10].hex(),
                    'last_10_bytes': raw_data[-10:].hex(),
                    'files_in_archive': sop_zip.namelist()
                }
        except Exception as e:
            return {'error': str(e)}
    
    def generate_report(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        metadata = self.get_metadata()
        record_stats = self.analyze_records()
        tables = self.analyze_tables()
        actions = self.get_actions_summary()
        
        return {
            'metadata': metadata,
            'record_statistics': {
                'total_records': record_stats.total,
                'delete_operations': record_stats.deletes,
                'strong_overwrites': record_stats.strong_overwrites,
                'actions_breakdown': actions
            },
            'tables': [
                {
                    'name': table.name,
                    'record_count': table.record_count,
                    'actions': table.actions
                }
                for table in tables
            ],
            'file_info': {
                'file_path': str(self.sop_file_path),
                'file_size': self.sop_file_path.stat().st_size,
                'analysis_date': datetime.datetime.now().isoformat()
            }
        }


class OutputFormatter:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞"""
    
    @staticmethod
    def print_table(headers: List[str], rows: List[List[str]], title: str = ""):
        """–ü–µ—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã"""
        if title:
            print(f"\n{title}")
            print("=" * 60)
        
        if not rows:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            return
        
        # –í—ã—á–∏—Å–ª—è–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–æ–∫
        col_widths = []
        for i, header in enumerate(headers):
            max_width = len(header)
            for row in rows:
                if i < len(row):
                    max_width = max(max_width, len(str(row[i])))
            col_widths.append(max_width + 2)
        
        # –ü–µ—á–∞—Ç–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        header_line = "".join(f"{header:<{col_widths[i]}}" for i, header in enumerate(headers))
        print(header_line)
        print("-" * len(header_line))
        
        # –ü–µ—á–∞—Ç–∞–µ–º —Å—Ç—Ä–æ–∫–∏
        for row in rows:
            line = "".join(f"{str(cell):<{col_widths[i]}}" for i, cell in enumerate(row))
            print(line)
    
    @staticmethod
    def print_metadata(metadata: Dict[str, Any]):
        """–ü–µ—á–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        print("\nüì¶ –ú–ï–¢–ê–î–ê–ù–ù–´–ï –ü–ê–ö–ï–¢–ê")
        print("=" * 40)
        for key, value in metadata.items():
            print(f"{key:>20}: {value}")
    
    @staticmethod
    def print_record_stats(stats: RecordStats, actions: Dict[str, int]):
        """–ü–µ—á–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–ø–∏—Å–µ–π"""
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ó–ê–ü–ò–°–ï–ô")
        print("=" * 40)
        print(f"{'–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π':>20}: {stats.total}")
        print(f"{'–û–ø–µ—Ä–∞—Ü–∏–π —É–¥–∞–ª–µ–Ω–∏—è':>20}: {stats.deletes}")
        print(f"{'–°–∏–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–∑–∞–ø–∏—Å–µ–π':>20}: {stats.strong_overwrites}")
        
        if actions:
            print(f"\n{'–î–µ–π—Å—Ç–≤–∏—è':>20}:")
            for action, count in sorted(actions.items()):
                print(f"{'':>22}  {action}: {count}")
    
    @staticmethod
    def print_tables_summary(tables: List[TableInfo]):
        """–ü–µ—á–∞—Ç—å —Å–≤–æ–¥–∫–∏ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º"""
        if not tables:
            return
        
        headers = ["–¢–∞–±–ª–∏—Ü–∞", "–ó–∞–ø–∏—Å–µ–π", "–î–µ–π—Å—Ç–≤–∏—è"]
        rows = []
        
        for table in tables:
            actions_str = ", ".join(f"{k}:{v}" for k, v in table.actions.items())
            rows.append([table.name, str(table.record_count), actions_str])
        
        OutputFormatter.print_table(headers, rows, "üóÉÔ∏è –¢–ê–ë–õ–ò–¶–´")
    
    @staticmethod
    def print_raw_data_info(info: Dict[str, Any]):
        """–ü–µ—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("\nüîß –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø")
        print("=" * 40)
        for key, value in info.items():
            if key == 'files_in_archive':
                print(f"{'–§–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤–µ':>20}:")
                for file in value:
                    print(f"{'':>22}  {file}")
            else:
                print(f"{key:>20}: {value}")


def main():
    parser = argparse.ArgumentParser(
        description='SOP Analyzer - –ê–Ω–∞–ª–∏–∑ –ø–∞–∫–µ—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö .sop',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s package.sop                    # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
  %(prog)s package.sop --metadata         # –¢–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
  %(prog)s package.sop --stats            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø–∏—Å–µ–π
  %(prog)s package.sop --tables           # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∞–±–ª–∏—Ü–∞—Ö
  %(prog)s package.sop --json             # –í—ã–≤–æ–¥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
  %(prog)s package.sop --debug            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        """
    )
    
    parser.add_argument('sop_file', help='–ü—É—Ç—å –∫ .sop —Ñ–∞–π–ª—É')
    parser.add_argument('--metadata', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç–∞')
    parser.add_argument('--stats', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–ø–∏—Å–µ–π')
    parser.add_argument('--tables', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–±–ª–∏—Ü–∞—Ö')
    parser.add_argument('--json', action='store_true', help='–í—ã–≤–æ–¥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON')
    parser.add_argument('--debug', action='store_true', help='–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è')
    parser.add_argument('--verbose', '-v', action='store_true', help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞
    if not Path(args.sop_file).exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª {args.sop_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)
    
    try:
        analyzer = SOPAnalyzer(args.sop_file)
        
        # –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏
        if args.debug:
            raw_info = analyzer.get_raw_data_info()
            OutputFormatter.print_raw_data_info(raw_info)
            return
        
        # JSON –≤—ã–≤–æ–¥
        if args.json:
            report = analyzer.generate_report()
            print(json.dumps(report, indent=2, ensure_ascii=False))
            return
        
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if args.metadata:
            OutputFormatter.print_metadata(analyzer.get_metadata())
        elif args.stats:
            stats = analyzer.analyze_records()
            actions = analyzer.get_actions_summary()
            OutputFormatter.print_record_stats(stats, actions)
        elif args.tables:
            tables = analyzer.analyze_tables()
            OutputFormatter.print_tables_summary(tables)
        else:
            # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
            metadata = analyzer.get_metadata()
            stats = analyzer.analyze_records()
            actions = analyzer.get_actions_summary()
            tables = analyzer.analyze_tables()
            
            OutputFormatter.print_metadata(metadata)
            OutputFormatter.print_record_stats(stats, actions)
            OutputFormatter.print_tables_summary(tables)
            
            if args.verbose:
                print(f"\nüìÅ –§–∞–π–ª: {args.sop_file}")
                print(f"üìè –†–∞–∑–º–µ—Ä: {Path(args.sop_file).stat().st_size} –±–∞–π—Ç")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
        try:
            analyzer = SOPAnalyzer(args.sop_file)
            raw_info = analyzer.get_raw_data_info()
            print("\nüí° –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
            OutputFormatter.print_raw_data_info(raw_info)
        except:
            pass
        
        sys.exit(1)


if __name__ == "__main__":
    main()